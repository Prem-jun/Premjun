{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 9, 'max_features': 4, 'min_samples_leaf': 4}\n",
      "Best score is 0.9106060606060605\n",
      "None\n",
      "[[10  0]\n",
      " [ 3 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       1.00      0.79      0.88        14\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.88      0.89      0.87        24\n",
      "weighted avg       0.90      0.88      0.88        24\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dt_optNorCCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f9d267890d8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_optNorCCA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_optNorCCA' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn import tree\n",
    "\n",
    "df = pd.read_excel('D:/KKU/AjOff/AjOffData.xlsx',sheet_name='CutoffNorVsCCA')\n",
    "y=df.iloc[:,[3]]\n",
    "X=df.iloc[:,[4,5,6,7,8]]\n",
    "## Split train and test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=42) #best\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=30) #best\n",
    "\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [9,6,3], \n",
    "              \"max_features\": [1,2,3,4, 5],\n",
    "              \"min_samples_leaf\": [1,2,3,4,5,6,7,8,9,10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Initiate the decision tree\n",
    "dt = DecisionTreeClassifier(random_state=43)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = GridSearchCV(dt, param_dist, cv=5) #GridSearchCV\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "print(tree_cv.scoring)\n",
    "# tree_cv.best_estimator_ => Get the best parameter\n",
    "# tree_cv.cv_results_ => Get the all result of grid search \n",
    "\n",
    "## Create Tree from optimal parameters\n",
    "#dt_optNorCCA = DecisionTreeClassifier(criterion='gini',max_depth=9,max_features=5,min_samples_leaf=2,random_state=43)\n",
    "#dt_optNorCCA.fit(X_train,y_train)\n",
    "#y_pred=dt_optNorCCA.predict(X_test)\n",
    "\n",
    "# Create the fine-tuned tree\n",
    "dt_OptNorCCA = tree_cv.best_estimator_\n",
    "dt_OptNorCCA.fit(X_train,y_train)\n",
    "y_pred=dt_OptNorCCA.predict(X_test)\n",
    "#print(tree_cv.best_estimator_)\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "r = export_text(dt_optNorCCA)\n",
    "print(r)\n",
    "import pickle\n",
    "s = pickle.dumps(dt_optNorCCA)\n",
    "#clf2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 9, 'max_features': 3, 'min_samples_leaf': 7}\n",
      "Best score is 0.75\n",
      "None\n",
      "[[11  3]\n",
      " [ 2  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.81        14\n",
      "           1       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.79      0.79      0.79        24\n",
      "weighted avg       0.80      0.79      0.79        24\n",
      "\n",
      "|--- feature_4 <= 0.50\n",
      "|   |--- feature_2 <= 0.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_2 >  0.50\n",
      "|   |   |--- class: 0\n",
      "|--- feature_4 >  0.50\n",
      "|   |--- feature_2 <= 0.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_2 >  0.50\n",
      "|   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn import tree\n",
    "\n",
    "df = pd.read_excel('D:/KKU/AjOff/AjOffData.xlsx',sheet_name='Cutoff NonCCAVsCCA')\n",
    "y=df.iloc[:,[3]]\n",
    "X=df.iloc[:,[4,5,6,7,8]]\n",
    "## Split train and test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=20)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=53)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=28)\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [9,6,3], \n",
    "              \"max_features\": [1,2,3,4, 5],\n",
    "              \"min_samples_leaf\": [1,2,3,4,5,6,7,8,9,10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Initiate the decision tree\n",
    "dt = DecisionTreeClassifier(random_state=43)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = GridSearchCV(dt, param_dist, cv=5) #GridSearchCV\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "print(tree_cv.scoring)\n",
    "# tree_cv.best_estimator_ => Get the best parameter\n",
    "# tree_cv.cv_results_ => Get the all result of grid search \n",
    "\n",
    "## Create Tree from optimal parameters\n",
    "#dt_optNorCCA = DecisionTreeClassifier(criterion='gini',max_depth=9,max_features=5,min_samples_leaf=2,random_state=43)\n",
    "#dt_optNorCCA.fit(X_train,y_train)\n",
    "#y_pred=dt_optNorCCA.predict(X_test)\n",
    "\n",
    "#tree_cv.best_estimator_.fit(X_train,y_train)\n",
    "dt_optNorCCA = tree_cv.best_estimator_\n",
    "dt_optNorCCA.fit(X_train,y_train)\n",
    "y_pred=dt_optNorCCA.predict(X_test)\n",
    "#print(tree_cv.best_estimator_)\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "r = export_text(dt_optNorCCA)\n",
    "print(r)\n",
    "import pickle\n",
    "s = pickle.dumps(dt_optNorCCA)\n",
    "#clf2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 9, 'max_features': 1, 'min_samples_leaf': 4}\n",
      "Best score is 0.8227272727272729\n",
      "None\n",
      "[[10  3]\n",
      " [ 2  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80        13\n",
      "           1       0.75      0.82      0.78        11\n",
      "\n",
      "    accuracy                           0.79        24\n",
      "   macro avg       0.79      0.79      0.79        24\n",
      "weighted avg       0.80      0.79      0.79        24\n",
      "\n",
      "|--- feature_0 <= 0.50\n",
      "|   |--- feature_3 <= 0.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 >  0.50\n",
      "|   |   |--- feature_1 <= 0.50\n",
      "|   |   |   |--- feature_2 <= 0.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_2 >  0.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_1 >  0.50\n",
      "|   |   |   |--- feature_2 <= 0.50\n",
      "|   |   |   |   |--- feature_4 <= 0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_4 >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_2 >  0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|--- feature_0 >  0.50\n",
      "|   |--- feature_1 <= 0.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_1 >  0.50\n",
      "|   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn import tree\n",
    "\n",
    "df = pd.read_excel('D:/KKU/AjOff/AjOffData.xlsx',sheet_name='Cutoff NorVsNonCCA')\n",
    "y=df.iloc[:,[3]]\n",
    "X=df.iloc[:,[4,5,6,7,8]]\n",
    "## Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [9,6,3], \n",
    "              \"max_features\": [1,2,3,4, 5],\n",
    "              \"min_samples_leaf\": [1,2,3,4,5,6,7,8,9,10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Initiate the decision tree\n",
    "dt = DecisionTreeClassifier(random_state=43)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = GridSearchCV(dt, param_dist, cv=5) #GridSearchCV\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "print(tree_cv.scoring)\n",
    "# tree_cv.best_estimator_ => Get the best parameter\n",
    "# tree_cv.cv_results_ => Get the all result of grid search \n",
    "\n",
    "## Create Tree from optimal parameters\n",
    "#dt_optNorCCA = DecisionTreeClassifier(criterion='gini',max_depth=9,max_features=5,min_samples_leaf=2,random_state=43)\n",
    "#dt_optNorCCA.fit(X_train,y_train)\n",
    "#y_pred=dt_optNorCCA.predict(X_test)\n",
    "\n",
    "#tree_cv.best_estimator_.fit(X_train,y_train)\n",
    "dt_optNorCCA = tree_cv.best_estimator_\n",
    "dt_optNorCCA.fit(X_train,y_train)\n",
    "y_pred=dt_optNorCCA.predict(X_test)\n",
    "#print(tree_cv.best_estimator_)\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "r = export_text(dt_optNorCCA)\n",
    "print(r)\n",
    "import pickle\n",
    "s = pickle.dumps(dt_optNorCCA)\n",
    "#clf2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00159521, 0.00159583, 0.00179524, 0.00139618, 0.00159574,\n",
       "        0.00139627, 0.00159564, 0.00139627, 0.00139613, 0.00139637,\n",
       "        0.00139885, 0.00159564, 0.00139623, 0.00139623, 0.00159588,\n",
       "        0.00159578, 0.00159569, 0.00159564, 0.00159578, 0.00159574,\n",
       "        0.00199451, 0.00159578, 0.00159578, 0.00159574, 0.00139613,\n",
       "        0.00139637, 0.00139637, 0.00139627, 0.00139618, 0.00159564,\n",
       "        0.00140858, 0.0012898 , 0.00159574, 0.00159578, 0.00179515,\n",
       "        0.00179524, 0.00139618, 0.00159564, 0.00159578, 0.00159574,\n",
       "        0.00139623, 0.00159836, 0.00159578, 0.00139632, 0.00139627,\n",
       "        0.00179524, 0.00159569, 0.00179515, 0.00159569, 0.00159574,\n",
       "        0.00139632, 0.00159583, 0.00159569, 0.00159597, 0.00179529,\n",
       "        0.00159574, 0.00139627, 0.00159578, 0.00159578, 0.00159583,\n",
       "        0.00159583, 0.00159574, 0.00139637, 0.0017952 , 0.00179524,\n",
       "        0.00159583, 0.0017952 , 0.00159574, 0.00159588, 0.00139627,\n",
       "        0.00159574, 0.00159569, 0.00159569, 0.00159574, 0.00159578,\n",
       "        0.0017952 , 0.00139627, 0.00159574, 0.00159583, 0.00139627,\n",
       "        0.00159578, 0.00159583, 0.00179524, 0.00159583, 0.00159564,\n",
       "        0.00219393, 0.00199738, 0.00199409, 0.00199466, 0.00159583,\n",
       "        0.0021935 , 0.00138826, 0.00200644, 0.00159335, 0.00139813,\n",
       "        0.00159521, 0.00139594, 0.00139327, 0.00139713, 0.00139604,\n",
       "        0.00139494, 0.00119615, 0.00158954, 0.00139589, 0.00139885,\n",
       "        0.00158691, 0.00139642, 0.00178685, 0.00178981, 0.00139904,\n",
       "        0.00139728, 0.00159535, 0.0013979 , 0.00119634, 0.00139651,\n",
       "        0.00179558, 0.00138836, 0.00160408, 0.00159535, 0.00139661,\n",
       "        0.00139937, 0.00139594, 0.00139508, 0.00139356, 0.00159435,\n",
       "        0.00139394, 0.00139456, 0.00139489, 0.00139513, 0.00139832,\n",
       "        0.00139737, 0.00159426, 0.00139651, 0.00178738, 0.00180011,\n",
       "        0.00160332, 0.0013967 , 0.00139365, 0.00159755, 0.00139594,\n",
       "        0.00139575, 0.00139642, 0.00139766, 0.00139799, 0.00139551,\n",
       "        0.00139642, 0.0015975 , 0.00159812, 0.00139647, 0.00139537,\n",
       "        0.00159612, 0.00139413, 0.0015924 , 0.00159984, 0.0013886 ,\n",
       "        0.0018002 , 0.00198641, 0.00199752, 0.00159488, 0.00140309,\n",
       "        0.00140514, 0.0016016 , 0.00159793, 0.00180354, 0.00140347,\n",
       "        0.00139585, 0.00140634, 0.00139647, 0.00139666, 0.00139546,\n",
       "        0.00159464, 0.00139804, 0.00159698, 0.0015976 , 0.00158978,\n",
       "        0.00180154, 0.00119705, 0.00139604, 0.00159602, 0.00159435,\n",
       "        0.00199051, 0.00179377, 0.00139661, 0.00140023, 0.00178103,\n",
       "        0.00159726, 0.00179529, 0.00159411, 0.00139108, 0.00139027,\n",
       "        0.00159349, 0.00160279, 0.00159364, 0.0015964 , 0.00140219,\n",
       "        0.00139856, 0.0013967 , 0.00178466, 0.00180311, 0.00159545,\n",
       "        0.00139551, 0.00119743, 0.00139871, 0.00159249, 0.0015954 ,\n",
       "        0.00159454, 0.0015945 , 0.00139537, 0.00139546, 0.00139523,\n",
       "        0.00139756, 0.00159469, 0.00139809, 0.00139194, 0.00139484,\n",
       "        0.00179787, 0.00139399, 0.00159793, 0.00139985, 0.0015872 ,\n",
       "        0.00159535, 0.00159655, 0.00159559, 0.00219464, 0.00139108,\n",
       "        0.00140204, 0.00159578, 0.00159698, 0.00139933, 0.00139599,\n",
       "        0.00159502, 0.00139732, 0.00139685, 0.00159631, 0.00159678,\n",
       "        0.00139561, 0.00159512, 0.0013957 , 0.0013968 , 0.00159345,\n",
       "        0.00159607, 0.00139771, 0.00159335, 0.00139832, 0.00159588,\n",
       "        0.00139723, 0.00139613, 0.00159783, 0.00139585, 0.00139837,\n",
       "        0.00159349, 0.00159898, 0.0015974 , 0.00159431, 0.00159917,\n",
       "        0.00139432, 0.00139718, 0.00159497, 0.00159612, 0.00159507,\n",
       "        0.00139666, 0.00139656, 0.00179567, 0.00159531, 0.00159535,\n",
       "        0.00158935, 0.00160084, 0.00140319, 0.00139503, 0.00139561,\n",
       "        0.00159607, 0.00159545, 0.00139637, 0.00139689, 0.00139794,\n",
       "        0.00139527, 0.00139618, 0.00139599, 0.00139732, 0.00139709,\n",
       "        0.00139523, 0.00139737, 0.0013957 , 0.00159488, 0.00191035,\n",
       "        0.00138812, 0.00139537, 0.0013936 , 0.00138931, 0.00178761,\n",
       "        0.00159421, 0.00139527, 0.00140319, 0.00159149, 0.00159492,\n",
       "        0.00159459, 0.00159688, 0.0015955 , 0.00140014, 0.00139666]),\n",
       " 'std_fit_time': array([4.88188770e-04, 4.88499773e-04, 3.98850480e-04, 4.88616574e-04,\n",
       "        4.88421906e-04, 4.88538753e-04, 4.88538730e-04, 4.88636039e-04,\n",
       "        4.88655531e-04, 4.88655508e-04, 4.91707958e-04, 4.88636062e-04,\n",
       "        4.88577633e-04, 4.88674980e-04, 4.88636109e-04, 4.88558203e-04,\n",
       "        4.88675003e-04, 4.88636039e-04, 4.88558249e-04, 4.88616621e-04,\n",
       "        4.67203091e-07, 4.88460855e-04, 4.88558203e-04, 4.88616597e-04,\n",
       "        4.88655531e-04, 4.88558203e-04, 4.88558179e-04, 4.88636062e-04,\n",
       "        4.88713960e-04, 4.88636039e-04, 4.79024828e-04, 4.06091820e-04,\n",
       "        4.88616597e-04, 4.88558203e-04, 3.98922024e-04, 3.98850452e-04,\n",
       "        4.88616574e-04, 4.88636062e-04, 4.88558179e-04, 4.88616574e-04,\n",
       "        4.88577633e-04, 4.90782129e-04, 4.88558203e-04, 4.88694457e-04,\n",
       "        4.88538753e-04, 3.98969693e-04, 4.88577679e-04, 3.98802768e-04,\n",
       "        4.88577656e-04, 4.88519261e-04, 4.88499796e-04, 4.88694457e-04,\n",
       "        4.88577656e-04, 4.88811537e-04, 3.98755084e-04, 4.88519261e-04,\n",
       "        4.88538730e-04, 4.88558179e-04, 4.88752840e-04, 4.88597113e-04,\n",
       "        4.88694433e-04, 4.88519261e-04, 4.88558179e-04, 3.98826628e-04,\n",
       "        3.98850480e-04, 4.88597113e-04, 3.98826628e-04, 4.88421929e-04,\n",
       "        4.88538707e-04, 4.88538707e-04, 4.88519238e-04, 4.88577633e-04,\n",
       "        4.88674980e-04, 4.88616574e-04, 4.88558179e-04, 3.98945819e-04,\n",
       "        4.88733375e-04, 4.88616574e-04, 4.88499773e-04, 4.88636039e-04,\n",
       "        4.88655508e-04, 4.88597136e-04, 3.98850480e-04, 4.88499796e-04,\n",
       "        4.88538730e-04, 7.46608152e-04, 5.53747360e-06, 6.31385362e-04,\n",
       "        6.30977324e-04, 4.88499820e-04, 7.45894716e-04, 5.06828136e-04,\n",
       "        1.08312382e-05, 4.85906283e-04, 4.86768987e-04, 4.88286219e-04,\n",
       "        4.90565864e-04, 4.91024100e-04, 4.88335264e-04, 4.89036727e-04,\n",
       "        4.89183274e-04, 3.99006781e-04, 4.68083451e-04, 4.87102482e-04,\n",
       "        4.88209216e-04, 5.00316102e-04, 4.89499414e-04, 3.94298679e-04,\n",
       "        3.96976972e-04, 4.86872875e-04, 4.88219746e-04, 4.90254730e-04,\n",
       "        4.89074591e-04, 3.98662369e-04, 4.89221228e-04, 3.99821613e-04,\n",
       "        4.94658131e-04, 4.92595310e-04, 4.89782344e-04, 4.86529232e-04,\n",
       "        4.88828063e-04, 4.90901481e-04, 4.88943218e-04, 4.90685292e-04,\n",
       "        4.88076349e-04, 4.90377548e-04, 4.89662761e-04, 4.89686169e-04,\n",
       "        4.86073789e-04, 4.90664671e-04, 4.85046905e-04, 4.89456850e-04,\n",
       "        4.89619928e-04, 3.95328931e-04, 4.01877650e-04, 4.96504671e-04,\n",
       "        4.88385556e-04, 4.89737218e-04, 4.88449525e-04, 4.88519890e-04,\n",
       "        4.89559503e-04, 4.87060156e-04, 4.91517752e-04, 4.88601208e-04,\n",
       "        4.87898965e-04, 4.87651363e-04, 4.90759603e-04, 4.85703553e-04,\n",
       "        4.89261958e-04, 4.89182139e-04, 4.93221064e-04, 4.84074308e-04,\n",
       "        5.00100096e-04, 4.93111514e-04, 4.78649733e-04, 3.80409305e-04,\n",
       "        1.46828684e-05, 1.80376852e-05, 4.89170356e-04, 4.81694539e-04,\n",
       "        4.82095446e-04, 4.80223164e-04, 4.89142695e-04, 3.98106217e-04,\n",
       "        4.97584558e-04, 4.88717510e-04, 4.95934202e-04, 4.90336785e-04,\n",
       "        4.88623368e-04, 4.90765242e-04, 4.90159505e-04, 4.87589518e-04,\n",
       "        4.88073018e-04, 4.85685258e-04, 4.79841329e-04, 3.91904144e-04,\n",
       "        3.99026109e-04, 4.89030776e-04, 4.88175263e-04, 4.85850862e-04,\n",
       "        2.82263433e-05, 3.99902052e-04, 4.91073043e-04, 4.81462434e-04,\n",
       "        3.93231487e-04, 4.88720627e-04, 3.98434156e-04, 4.89152340e-04,\n",
       "        4.94924045e-04, 4.79574391e-04, 4.93016177e-04, 4.79725426e-04,\n",
       "        4.86751891e-04, 4.89359077e-04, 4.82342727e-04, 4.85898959e-04,\n",
       "        4.88383880e-04, 3.95906541e-04, 4.03340861e-04, 4.89454968e-04,\n",
       "        4.89263329e-04, 3.96686721e-04, 4.86694179e-04, 4.91666990e-04,\n",
       "        4.89321630e-04, 4.90467687e-04, 4.89942242e-04, 4.87541443e-04,\n",
       "        4.88521914e-04, 4.89591539e-04, 4.85738531e-04, 4.87968798e-04,\n",
       "        4.91454456e-04, 4.89176301e-04, 4.91665834e-04, 3.94260958e-04,\n",
       "        4.91313405e-04, 4.86137211e-04, 4.87566813e-04, 4.82675911e-04,\n",
       "        4.86474275e-04, 4.84998586e-04, 4.88209454e-04, 7.44381185e-04,\n",
       "        4.92488895e-04, 4.96034941e-04, 4.89436316e-04, 4.86716131e-04,\n",
       "        4.92090204e-04, 4.86828680e-04, 4.88229210e-04, 4.87878599e-04,\n",
       "        4.91197972e-04, 4.88792618e-04, 4.87723945e-04, 4.91237414e-04,\n",
       "        4.90351003e-04, 4.87354659e-04, 4.89094749e-04, 4.91631334e-04,\n",
       "        4.90160874e-04, 4.85925318e-04, 4.89494885e-04, 4.87355219e-04,\n",
       "        4.89612776e-04, 4.88052804e-04, 4.74752289e-04, 4.87221825e-04,\n",
       "        4.92109083e-04, 4.87901155e-04, 4.89614541e-04, 4.87972945e-04,\n",
       "        4.87270371e-04, 4.89895428e-04, 4.85809354e-04, 4.89567491e-04,\n",
       "        4.88871617e-04, 4.90914875e-04, 4.86450063e-04, 4.90313530e-04,\n",
       "        4.87547865e-04, 4.88208452e-04, 3.97158599e-04, 4.89072220e-04,\n",
       "        4.87141882e-04, 4.82681941e-04, 4.92667257e-04, 4.98856648e-04,\n",
       "        4.89614258e-04, 4.88611772e-04, 4.88794107e-04, 4.90722695e-04,\n",
       "        4.87786453e-04, 4.89200624e-04, 4.89029288e-04, 4.87703241e-04,\n",
       "        4.88037182e-04, 4.90431303e-04, 4.87780253e-04, 4.87794704e-04,\n",
       "        4.89695023e-04, 4.89011420e-04, 4.88135826e-04, 4.88504381e-04,\n",
       "        1.48549171e-04, 4.76765446e-04, 4.88407419e-04, 4.86640306e-04,\n",
       "        4.78253203e-04, 4.02546635e-04, 4.90202458e-04, 4.90442013e-04,\n",
       "        4.98257129e-04, 4.91591369e-04, 4.87377254e-04, 4.89002502e-04,\n",
       "        4.87702752e-04, 4.90077100e-04, 4.86117829e-04, 4.91051365e-04]),\n",
       " 'mean_score_time': array([0.00079827, 0.00059838, 0.00019941, 0.00059843, 0.00039897,\n",
       "        0.00059838, 0.00039897, 0.00059838, 0.00059848, 0.00059834,\n",
       "        0.00039897, 0.00039897, 0.00059843, 0.00059838, 0.00039887,\n",
       "        0.00039887, 0.00039897, 0.00039902, 0.00039887, 0.00059848,\n",
       "        0.00059853, 0.00039892, 0.00039887, 0.00039887, 0.00039897,\n",
       "        0.00039883, 0.00039887, 0.00039887, 0.00059838, 0.00039897,\n",
       "        0.00058618, 0.00059848, 0.00039892, 0.00039887, 0.00019946,\n",
       "        0.00039892, 0.00039897, 0.00039897, 0.00039887, 0.00039897,\n",
       "        0.00059838, 0.00059576, 0.00019941, 0.00039887, 0.00059838,\n",
       "        0.00019946, 0.00079794, 0.00039897, 0.00059843, 0.00039887,\n",
       "        0.00039892, 0.00039892, 0.00039892, 0.00059848, 0.00039887,\n",
       "        0.00039897, 0.00059843, 0.00039892, 0.00039892, 0.00039887,\n",
       "        0.00039883, 0.00039892, 0.00059838, 0.00019946, 0.00039887,\n",
       "        0.00039892, 0.00019946, 0.00039892, 0.00059829, 0.00059834,\n",
       "        0.00039887, 0.00059843, 0.00039897, 0.00039887, 0.00039887,\n",
       "        0.00019946, 0.00059838, 0.00039892, 0.00039892, 0.00059843,\n",
       "        0.00039887, 0.00039887, 0.00019946, 0.00059834, 0.00059838,\n",
       "        0.00059857, 0.00059552, 0.00059896, 0.00019946, 0.00059838,\n",
       "        0.00088525, 0.00084333, 0.0003962 , 0.00040145, 0.00059681,\n",
       "        0.00039921, 0.00059915, 0.00060139, 0.00059772, 0.00059867,\n",
       "        0.00039845, 0.00059767, 0.00039601, 0.00039907, 0.0003973 ,\n",
       "        0.00040898, 0.00059729, 0.00039849, 0.00040379, 0.00059948,\n",
       "        0.0003984 , 0.00039988, 0.00059776, 0.0005991 , 0.00039916,\n",
       "        0.00019941, 0.00060558, 0.00039716, 0.00039988, 0.00059776,\n",
       "        0.00059743, 0.00040069, 0.00039978, 0.00039954, 0.00040026,\n",
       "        0.00060077, 0.0003993 , 0.00059905, 0.00040064, 0.00059829,\n",
       "        0.00059581, 0.00039907, 0.00059814, 0.00019951, 0.00039911,\n",
       "        0.00059781, 0.00059838, 0.00039988, 0.00039825, 0.00059853,\n",
       "        0.00059915, 0.00039868, 0.00039968, 0.00059791, 0.00039907,\n",
       "        0.00039697, 0.00039849, 0.00039649, 0.00039859, 0.00039964,\n",
       "        0.00039892, 0.00059919, 0.00040298, 0.00059342, 0.00079842,\n",
       "        0.00040212, 0.00041022, 0.        , 0.00059924, 0.00079036,\n",
       "        0.00058861, 0.00040007, 0.00019922, 0.0003828 , 0.00059857,\n",
       "        0.00059886, 0.00058947, 0.00059805, 0.0005981 , 0.00059981,\n",
       "        0.0004005 , 0.00039892, 0.00039825, 0.00059609, 0.00039806,\n",
       "        0.00059385, 0.00060668, 0.00039849, 0.00039864, 0.00059233,\n",
       "        0.00020342, 0.00019965, 0.00079713, 0.0007936 , 0.00061274,\n",
       "        0.00039845, 0.00020747, 0.00039878, 0.0004055 , 0.00059705,\n",
       "        0.00040054, 0.00039916, 0.00040164, 0.00059023, 0.00059896,\n",
       "        0.00059543, 0.00060058, 0.00059834, 0.00039883, 0.00039949,\n",
       "        0.00039916, 0.00059896, 0.00039945, 0.00039892, 0.00039921,\n",
       "        0.00039959, 0.00040073, 0.00059872, 0.00059848, 0.00060034,\n",
       "        0.00059576, 0.00040059, 0.00039945, 0.00040073, 0.00039921,\n",
       "        0.        , 0.00060081, 0.00039682, 0.00059643, 0.00060644,\n",
       "        0.00039959, 0.00039787, 0.00039835, 0.00039167, 0.00080838,\n",
       "        0.00039907, 0.0003993 , 0.0003974 , 0.00039873, 0.00039954,\n",
       "        0.00039921, 0.00059752, 0.00059938, 0.00039878, 0.00059767,\n",
       "        0.00059938, 0.00040088, 0.00059776, 0.00059829, 0.00039892,\n",
       "        0.00039945, 0.00059633, 0.00040064, 0.00039816, 0.00039935,\n",
       "        0.00059729, 0.00059857, 0.00039792, 0.00059924, 0.00059729,\n",
       "        0.00039997, 0.00039825, 0.00059586, 0.00039887, 0.00039635,\n",
       "        0.00059843, 0.00059738, 0.00039945, 0.00039787, 0.00039892,\n",
       "        0.00059791, 0.000598  , 0.0003984 , 0.00039935, 0.00039964,\n",
       "        0.00059814, 0.0007925 , 0.00059924, 0.00059977, 0.00059876,\n",
       "        0.00039902, 0.00039959, 0.00059772, 0.00059791, 0.00059762,\n",
       "        0.0004003 , 0.00039849, 0.00039983, 0.0003984 , 0.00059819,\n",
       "        0.0003984 , 0.00059729, 0.00059886, 0.00039873, 0.00012503,\n",
       "        0.00039759, 0.00039845, 0.00040097, 0.00039911, 0.00040407,\n",
       "        0.00060706, 0.00059166, 0.00039878, 0.00039973, 0.00040007,\n",
       "        0.00039954, 0.00039802, 0.00039921, 0.00039897, 0.00039921]),\n",
       " 'std_score_time': array([0.00039914, 0.00048858, 0.00039883, 0.00048862, 0.00048864,\n",
       "        0.00048858, 0.00048864, 0.00048858, 0.00048866, 0.00048854,\n",
       "        0.00048864, 0.00048864, 0.00048862, 0.00048858, 0.00048852,\n",
       "        0.00048852, 0.00048864, 0.00048869, 0.00048852, 0.00048866,\n",
       "        0.00048869, 0.00048858, 0.00048852, 0.00048852, 0.00048864,\n",
       "        0.00048846, 0.00048852, 0.00048852, 0.00048858, 0.00048864,\n",
       "        0.00047914, 0.00048866, 0.00048858, 0.00048852, 0.00039892,\n",
       "        0.00048858, 0.00048864, 0.00048864, 0.00048852, 0.00048864,\n",
       "        0.00048858, 0.00048646, 0.00039883, 0.00048852, 0.00048858,\n",
       "        0.00039892, 0.00039897, 0.00048864, 0.00048862, 0.00048852,\n",
       "        0.00048858, 0.00048858, 0.00048858, 0.00048866, 0.00048852,\n",
       "        0.00048864, 0.00048862, 0.00048858, 0.00048858, 0.00048852,\n",
       "        0.00048846, 0.00048858, 0.00048858, 0.00039892, 0.00048852,\n",
       "        0.00048858, 0.00039892, 0.00048858, 0.0004885 , 0.00048854,\n",
       "        0.00048852, 0.00048862, 0.00048864, 0.00048852, 0.00048852,\n",
       "        0.00039892, 0.00048858, 0.00048858, 0.00048858, 0.00048862,\n",
       "        0.00048852, 0.00048852, 0.00039892, 0.00048854, 0.00048858,\n",
       "        0.00048873, 0.00048627, 0.00048918, 0.00039892, 0.00048858,\n",
       "        0.00047195, 0.00043381, 0.00048527, 0.00049171, 0.0004873 ,\n",
       "        0.00048893, 0.0004892 , 0.00049107, 0.00048803, 0.00048881,\n",
       "        0.00048799, 0.000488  , 0.00048503, 0.00048876, 0.0004866 ,\n",
       "        0.00050116, 0.00048769, 0.00048805, 0.0004946 , 0.00048947,\n",
       "        0.00048794, 0.00048975, 0.00048808, 0.00048917, 0.00048887,\n",
       "        0.00039883, 0.00049466, 0.00048643, 0.00048975, 0.00048808,\n",
       "        0.0004878 , 0.00049075, 0.00048963, 0.00048934, 0.00049022,\n",
       "        0.00049054, 0.00048905, 0.00048912, 0.00049069, 0.0004885 ,\n",
       "        0.0004865 , 0.00048875, 0.0004884 , 0.00039902, 0.00048881,\n",
       "        0.00048817, 0.00048858, 0.00048975, 0.00048776, 0.00048869,\n",
       "        0.00048921, 0.00048829, 0.00048951, 0.00048819, 0.00048875,\n",
       "        0.00048619, 0.00048805, 0.0004856 , 0.00048817, 0.00048945,\n",
       "        0.00048858, 0.00048929, 0.00049361, 0.00048516, 0.00039925,\n",
       "        0.00049251, 0.00050244, 0.        , 0.00048928, 0.00039536,\n",
       "        0.00048088, 0.00048998, 0.00039845, 0.00046885, 0.00048873,\n",
       "        0.00048897, 0.00048165, 0.00048831, 0.00048835, 0.00048978,\n",
       "        0.00049051, 0.00048858, 0.00048776, 0.00048674, 0.00048753,\n",
       "        0.00048494, 0.00049555, 0.00048805, 0.00048823, 0.00048374,\n",
       "        0.00040684, 0.0003993 , 0.00039857, 0.00039704, 0.00050046,\n",
       "        0.000488  , 0.00041494, 0.0004884 , 0.0004968 , 0.00048749,\n",
       "        0.00049057, 0.00048887, 0.00049193, 0.00048213, 0.00048905,\n",
       "        0.00048618, 0.00049039, 0.00048854, 0.00048846, 0.00048928,\n",
       "        0.00048887, 0.00048906, 0.00048922, 0.00048858, 0.00048894,\n",
       "        0.0004894 , 0.0004908 , 0.00048885, 0.00048866, 0.00049018,\n",
       "        0.00048644, 0.00049063, 0.00048922, 0.00049082, 0.00048893,\n",
       "        0.        , 0.00049058, 0.00048602, 0.00048699, 0.00049531,\n",
       "        0.00048941, 0.0004873 , 0.00048788, 0.00047981, 0.00040435,\n",
       "        0.00048875, 0.00048905, 0.00048671, 0.00048834, 0.00048934,\n",
       "        0.00048893, 0.00048788, 0.0004894 , 0.0004884 , 0.000488  ,\n",
       "        0.00048941, 0.00049097, 0.00048807, 0.0004885 , 0.00048858,\n",
       "        0.00048922, 0.00048694, 0.00049068, 0.00048765, 0.0004891 ,\n",
       "        0.00048768, 0.00048873, 0.00048736, 0.00048928, 0.0004877 ,\n",
       "        0.00048987, 0.00048776, 0.00048652, 0.00048852, 0.00048544,\n",
       "        0.00048862, 0.00048776, 0.00048922, 0.0004873 , 0.00048858,\n",
       "        0.00048819, 0.00048827, 0.00048794, 0.0004891 , 0.00048946,\n",
       "        0.00048838, 0.00039638, 0.00048928, 0.00048971, 0.00048889,\n",
       "        0.00048869, 0.0004894 , 0.00048804, 0.00048819, 0.00048796,\n",
       "        0.00049027, 0.00048805, 0.00048969, 0.00048794, 0.00048842,\n",
       "        0.00048794, 0.00048768, 0.00048897, 0.00048834, 0.00025005,\n",
       "        0.00048694, 0.00048799, 0.0004911 , 0.00048881, 0.00049495,\n",
       "        0.00049583, 0.00048335, 0.00048841, 0.00048957, 0.00048998,\n",
       "        0.00048934, 0.00048747, 0.00048893, 0.00048864, 0.00048893]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                    9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6,\n",
       "                    7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4,\n",
       "                    5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2,\n",
       "                    3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                    9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6,\n",
       "                    7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4,\n",
       "                    5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2,\n",
       "                    3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                    9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6,\n",
       "                    7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4,\n",
       "                    5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2,\n",
       "                    3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                    9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 9,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 1,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 2,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 4,\n",
       "   'min_samples_leaf': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 1},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 2},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 7},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 9},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 3,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10}],\n",
       " 'split0_test_score': array([0.875 , 0.875 , 0.75  , 0.75  , 0.75  , 0.875 , 0.75  , 0.75  ,\n",
       "        0.75  , 0.75  , 0.75  , 0.625 , 0.875 , 0.75  , 0.8125, 0.625 ,\n",
       "        0.625 , 0.625 , 0.625 , 0.5625, 0.875 , 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.875 , 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.875 , 0.875 , 0.75  , 0.75  , 0.75  , 0.875 ,\n",
       "        0.75  , 0.75  , 0.75  , 0.75  , 0.75  , 0.625 , 0.875 , 0.75  ,\n",
       "        0.8125, 0.625 , 0.625 , 0.625 , 0.625 , 0.5625, 0.875 , 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.875 , 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.4375, 0.4375, 0.625 , 0.5625,\n",
       "        0.5625, 0.75  , 0.75  , 0.75  , 0.75  , 0.75  , 0.6875, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.625 , 0.625 , 0.625 , 0.625 , 0.5625,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875 , 0.875 ,\n",
       "        0.75  , 0.75  , 0.75  , 0.875 , 0.75  , 0.75  , 0.75  , 0.75  ,\n",
       "        0.75  , 0.625 , 0.875 , 0.75  , 0.8125, 0.625 , 0.625 , 0.625 ,\n",
       "        0.625 , 0.5625, 0.875 , 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875 ,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.875 , 0.875 , 0.75  , 0.75  , 0.75  , 0.875 , 0.75  , 0.75  ,\n",
       "        0.75  , 0.75  , 0.75  , 0.625 , 0.875 , 0.75  , 0.8125, 0.625 ,\n",
       "        0.625 , 0.625 , 0.625 , 0.5625, 0.875 , 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.875 , 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.4375, 0.4375, 0.625 , 0.5625, 0.5625, 0.75  ,\n",
       "        0.75  , 0.75  , 0.75  , 0.75  , 0.6875, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.625 , 0.625 , 0.625 , 0.625 , 0.5625, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125]),\n",
       " 'split1_test_score': array([0.875 , 0.875 , 0.8125, 0.8125, 0.8125, 0.8125, 0.9375, 0.6875,\n",
       "        0.6875, 0.6875, 0.875 , 0.8125, 0.8125, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.6875, 0.6875, 0.6875, 0.875 , 0.875 , 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.8125, 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.9375, 0.6875, 0.6875, 0.6875, 0.875 , 0.8125, 0.8125, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.6875, 0.6875, 0.6875, 0.875 , 0.875 ,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.8125, 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.625 , 0.625 , 0.625 , 0.625 ,\n",
       "        0.625 , 0.625 , 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875,\n",
       "        0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875,\n",
       "        0.75  , 0.75  , 0.75  , 0.75  , 0.75  , 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.9375, 0.6875, 0.6875, 0.6875,\n",
       "        0.875 , 0.8125, 0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.6875,\n",
       "        0.6875, 0.6875, 0.875 , 0.875 , 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.8125, 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.8125, 0.8125, 0.8125, 0.8125, 0.9375, 0.6875,\n",
       "        0.6875, 0.6875, 0.875 , 0.8125, 0.8125, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.6875, 0.6875, 0.6875, 0.875 , 0.875 , 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.8125, 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 ,\n",
       "        0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875,\n",
       "        0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "        0.75  , 0.75  , 0.75  , 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 ]),\n",
       " 'split2_test_score': array([0.8125, 0.9375, 0.8125, 0.875 , 0.875 , 0.875 , 0.875 , 0.6875,\n",
       "        0.6875, 0.6875, 0.875 , 0.75  , 0.9375, 0.8125, 0.8125, 0.8125,\n",
       "        0.875 , 0.6875, 0.6875, 0.6875, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.8125, 0.9375, 0.8125, 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.6875, 0.6875, 0.6875, 0.875 , 0.75  , 0.9375, 0.8125,\n",
       "        0.8125, 0.8125, 0.875 , 0.6875, 0.6875, 0.6875, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.6875, 0.6875, 0.6875, 0.6875,\n",
       "        0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.625 , 0.625 ,\n",
       "        0.625 , 0.625 , 0.625 , 0.625 , 0.6875, 0.6875, 0.6875, 0.6875,\n",
       "        0.75  , 0.75  , 0.75  , 0.75  , 0.75  , 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.8125, 0.9375,\n",
       "        0.8125, 0.875 , 0.875 , 0.875 , 0.875 , 0.6875, 0.6875, 0.6875,\n",
       "        0.875 , 0.75  , 0.9375, 0.8125, 0.8125, 0.8125, 0.875 , 0.6875,\n",
       "        0.6875, 0.6875, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875 , 0.875 ,\n",
       "        0.875 , 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.8125, 0.8125,\n",
       "        0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.8125, 0.9375, 0.8125, 0.875 , 0.875 , 0.875 , 0.875 , 0.6875,\n",
       "        0.6875, 0.6875, 0.875 , 0.75  , 0.9375, 0.8125, 0.8125, 0.8125,\n",
       "        0.875 , 0.6875, 0.6875, 0.6875, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875,\n",
       "        0.6875, 0.6875, 0.6875, 0.6875, 0.625 , 0.625 , 0.625 , 0.625 ,\n",
       "        0.625 , 0.625 , 0.6875, 0.6875, 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "        0.75  , 0.75  , 0.75  , 0.8125, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375]),\n",
       " 'split3_test_score': array([0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.6875, 0.6875, 0.5625,\n",
       "        0.5625, 0.5625, 0.625 , 0.5625, 0.625 , 0.625 , 0.8125, 0.8125,\n",
       "        0.8125, 0.5625, 0.4375, 0.4375, 0.625 , 0.6875, 0.8125, 0.8125,\n",
       "        0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.875 , 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.75  , 0.8125, 0.8125, 0.8125, 0.8125, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.6875,\n",
       "        0.6875, 0.5625, 0.5625, 0.5625, 0.625 , 0.5625, 0.625 , 0.625 ,\n",
       "        0.8125, 0.8125, 0.8125, 0.5625, 0.4375, 0.4375, 0.625 , 0.6875,\n",
       "        0.8125, 0.8125, 0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 ,\n",
       "        0.875 , 0.8125, 0.8125, 0.8125, 0.8125, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.75  , 0.8125, 0.8125, 0.8125, 0.8125, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.6875, 0.6875, 0.6875, 0.6875,\n",
       "        0.6875, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.6875, 0.6875,\n",
       "        0.6875, 0.75  , 0.8125, 0.8125, 0.8125, 0.5625, 0.4375, 0.4375,\n",
       "        0.75  , 0.75  , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 ,\n",
       "        0.625 , 0.625 , 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.8125, 0.8125,\n",
       "        0.875 , 0.875 , 0.875 , 0.6875, 0.6875, 0.5625, 0.5625, 0.5625,\n",
       "        0.6875, 0.75  , 0.625 , 0.625 , 0.8125, 0.8125, 0.8125, 0.5625,\n",
       "        0.4375, 0.4375, 0.625 , 0.6875, 0.8125, 0.8125, 0.625 , 0.625 ,\n",
       "        0.625 , 0.625 , 0.625 , 0.625 , 0.875 , 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.75  , 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.8125, 0.8125, 0.875 , 0.875 , 0.875 , 0.6875, 0.6875, 0.5625,\n",
       "        0.5625, 0.5625, 0.6875, 0.75  , 0.625 , 0.625 , 0.8125, 0.8125,\n",
       "        0.8125, 0.5625, 0.4375, 0.4375, 0.625 , 0.6875, 0.8125, 0.8125,\n",
       "        0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.875 , 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.75  , 0.8125, 0.8125, 0.8125, 0.8125, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.5625,\n",
       "        0.5625, 0.5625, 0.5625, 0.5625, 0.6875, 0.6875, 0.6875, 0.75  ,\n",
       "        0.8125, 0.8125, 0.8125, 0.5625, 0.4375, 0.4375, 0.75  , 0.75  ,\n",
       "        0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 , 0.625 ,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375]),\n",
       " 'split4_test_score': array([0.875 , 0.875 , 0.6875, 0.6875, 0.6875, 0.375 , 0.375 , 0.375 ,\n",
       "        0.375 , 0.375 , 0.8125, 0.8125, 0.5625, 0.5625, 0.625 , 0.8125,\n",
       "        0.8125, 0.5625, 0.3125, 0.3125, 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.8125, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.8125, 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.875 , 0.875 , 0.6875, 0.6875, 0.6875, 0.375 ,\n",
       "        0.375 , 0.375 , 0.375 , 0.375 , 0.8125, 0.8125, 0.5625, 0.5625,\n",
       "        0.625 , 0.8125, 0.8125, 0.5625, 0.3125, 0.3125, 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "        0.8125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.8125, 0.875 , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.5   , 0.5   , 0.5   , 0.5   ,\n",
       "        0.5   , 0.375 , 0.375 , 0.375 , 0.375 , 0.375 , 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.5625, 0.3125, 0.3125,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.9375, 0.9375, 0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.875 , 0.875 ,\n",
       "        0.6875, 0.6875, 0.6875, 0.375 , 0.375 , 0.375 , 0.375 , 0.375 ,\n",
       "        0.8125, 0.8125, 0.5625, 0.5625, 0.625 , 0.8125, 0.8125, 0.5625,\n",
       "        0.3125, 0.3125, 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.9375, 0.9375, 0.8125, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.8125, 0.875 ,\n",
       "        0.875 , 0.875 , 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.875 , 0.875 , 0.6875, 0.6875, 0.6875, 0.375 , 0.375 , 0.375 ,\n",
       "        0.375 , 0.375 , 0.8125, 0.8125, 0.5625, 0.5625, 0.625 , 0.8125,\n",
       "        0.8125, 0.5625, 0.3125, 0.3125, 0.875 , 0.875 , 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.8125, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.8125, 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.5   , 0.5   , 0.5   , 0.5   , 0.5   , 0.375 ,\n",
       "        0.375 , 0.375 , 0.375 , 0.375 , 0.8125, 0.8125, 0.8125, 0.8125,\n",
       "        0.8125, 0.8125, 0.8125, 0.5625, 0.3125, 0.3125, 0.875 , 0.875 ,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "        0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375, 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.875 , 0.875 , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "        0.9375, 0.9375, 0.9375, 0.9375]),\n",
       " 'mean_test_score': array([0.85  , 0.875 , 0.7875, 0.8   , 0.8   , 0.725 , 0.725 , 0.6125,\n",
       "        0.6125, 0.6125, 0.7875, 0.7125, 0.7625, 0.7375, 0.8   , 0.8   ,\n",
       "        0.8125, 0.625 , 0.55  , 0.5375, 0.8125, 0.8125, 0.825 , 0.825 ,\n",
       "        0.7875, 0.7875, 0.7875, 0.7875, 0.8   , 0.8   , 0.8375, 0.85  ,\n",
       "        0.8625, 0.8625, 0.8625, 0.9   , 0.9   , 0.9   , 0.9   , 0.9   ,\n",
       "        0.8125, 0.85  , 0.85  , 0.85  , 0.85  , 0.9   , 0.9   , 0.9   ,\n",
       "        0.9   , 0.9   , 0.85  , 0.875 , 0.7875, 0.8   , 0.8   , 0.725 ,\n",
       "        0.725 , 0.6125, 0.6125, 0.6125, 0.7875, 0.7125, 0.7625, 0.7375,\n",
       "        0.8   , 0.8   , 0.8125, 0.625 , 0.55  , 0.5375, 0.8125, 0.8125,\n",
       "        0.825 , 0.825 , 0.7875, 0.7875, 0.7875, 0.7875, 0.8   , 0.8   ,\n",
       "        0.8375, 0.85  , 0.8625, 0.8625, 0.8625, 0.9   , 0.9   , 0.9   ,\n",
       "        0.9   , 0.9   , 0.8125, 0.85  , 0.85  , 0.85  , 0.85  , 0.9   ,\n",
       "        0.9   , 0.9   , 0.9   , 0.9   , 0.5875, 0.5875, 0.625 , 0.6125,\n",
       "        0.6125, 0.6   , 0.6125, 0.6125, 0.6125, 0.6125, 0.7   , 0.725 ,\n",
       "        0.725 , 0.7375, 0.75  , 0.7125, 0.725 , 0.625 , 0.55  , 0.5375,\n",
       "        0.7875, 0.7875, 0.7625, 0.7625, 0.7625, 0.7875, 0.7875, 0.7875,\n",
       "        0.8   , 0.8   , 0.8375, 0.8375, 0.8375, 0.8375, 0.85  , 0.9   ,\n",
       "        0.9   , 0.9   , 0.9   , 0.9   , 0.85  , 0.85  , 0.85  , 0.85  ,\n",
       "        0.8625, 0.9   , 0.9   , 0.9   , 0.9   , 0.9   , 0.85  , 0.875 ,\n",
       "        0.7875, 0.8   , 0.8   , 0.725 , 0.725 , 0.6125, 0.6125, 0.6125,\n",
       "        0.8   , 0.75  , 0.7625, 0.7375, 0.8   , 0.8   , 0.8125, 0.625 ,\n",
       "        0.55  , 0.5375, 0.8125, 0.8125, 0.825 , 0.825 , 0.7875, 0.7875,\n",
       "        0.7875, 0.7875, 0.8   , 0.8   , 0.8375, 0.85  , 0.8625, 0.8625,\n",
       "        0.8625, 0.9   , 0.9   , 0.9   , 0.9   , 0.9   , 0.8125, 0.85  ,\n",
       "        0.85  , 0.85  , 0.85  , 0.9   , 0.9   , 0.9   , 0.9   , 0.9   ,\n",
       "        0.85  , 0.875 , 0.7875, 0.8   , 0.8   , 0.725 , 0.725 , 0.6125,\n",
       "        0.6125, 0.6125, 0.8   , 0.75  , 0.7625, 0.7375, 0.8   , 0.8   ,\n",
       "        0.8125, 0.625 , 0.55  , 0.5375, 0.8125, 0.8125, 0.825 , 0.825 ,\n",
       "        0.7875, 0.7875, 0.7875, 0.7875, 0.8   , 0.8   , 0.8375, 0.85  ,\n",
       "        0.8625, 0.8625, 0.8625, 0.9   , 0.9   , 0.9   , 0.9   , 0.9   ,\n",
       "        0.8125, 0.85  , 0.85  , 0.85  , 0.85  , 0.9   , 0.9   , 0.9   ,\n",
       "        0.9   , 0.9   , 0.5875, 0.5875, 0.625 , 0.6125, 0.6125, 0.6   ,\n",
       "        0.6125, 0.6125, 0.6125, 0.6125, 0.7   , 0.725 , 0.725 , 0.7375,\n",
       "        0.75  , 0.7125, 0.725 , 0.625 , 0.55  , 0.5375, 0.7875, 0.7875,\n",
       "        0.7625, 0.7625, 0.7625, 0.7875, 0.7875, 0.7875, 0.8   , 0.8   ,\n",
       "        0.8375, 0.8375, 0.8375, 0.8375, 0.85  , 0.9   , 0.9   , 0.9   ,\n",
       "        0.9   , 0.9   , 0.85  , 0.85  , 0.85  , 0.85  , 0.8625, 0.9   ,\n",
       "        0.9   , 0.9   , 0.9   , 0.9   ]),\n",
       " 'std_test_score': array([0.03061862, 0.03952847, 0.06373774, 0.0728869 , 0.0728869 ,\n",
       "        0.1879162 , 0.19605484, 0.13346348, 0.13346348, 0.13346348,\n",
       "        0.09354143, 0.10155048, 0.14469796, 0.13346348, 0.1       ,\n",
       "        0.1       , 0.1045825 , 0.0559017 , 0.15      , 0.1457738 ,\n",
       "        0.09682458, 0.06846532, 0.025     , 0.025     , 0.08477912,\n",
       "        0.08477912, 0.08477912, 0.08477912, 0.1       , 0.1       ,\n",
       "        0.03061862, 0.05      , 0.04677072, 0.04677072, 0.04677072,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03952847, 0.03061862, 0.03061862, 0.03061862, 0.05      ,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03061862, 0.03952847, 0.06373774, 0.0728869 , 0.0728869 ,\n",
       "        0.1879162 , 0.19605484, 0.13346348, 0.13346348, 0.13346348,\n",
       "        0.09354143, 0.10155048, 0.14469796, 0.13346348, 0.1       ,\n",
       "        0.1       , 0.1045825 , 0.0559017 , 0.15      , 0.1457738 ,\n",
       "        0.09682458, 0.06846532, 0.025     , 0.025     , 0.08477912,\n",
       "        0.08477912, 0.08477912, 0.08477912, 0.1       , 0.1       ,\n",
       "        0.03061862, 0.05      , 0.04677072, 0.04677072, 0.04677072,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03952847, 0.03061862, 0.03061862, 0.03061862, 0.05      ,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.10155048, 0.10155048, 0.06846532, 0.0728869 , 0.0728869 ,\n",
       "        0.12869538, 0.13346348, 0.13346348, 0.13346348, 0.13346348,\n",
       "        0.06123724, 0.075     , 0.075     , 0.0728869 , 0.07905694,\n",
       "        0.08477912, 0.075     , 0.0559017 , 0.15      , 0.1457738 ,\n",
       "        0.05      , 0.05      , 0.08291562, 0.08291562, 0.08291562,\n",
       "        0.08477912, 0.08477912, 0.08477912, 0.1       , 0.1       ,\n",
       "        0.03061862, 0.03061862, 0.03061862, 0.03061862, 0.05      ,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03061862, 0.03061862, 0.03061862, 0.03061862, 0.04677072,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03061862, 0.03952847, 0.06373774, 0.0728869 , 0.0728869 ,\n",
       "        0.1879162 , 0.19605484, 0.13346348, 0.13346348, 0.13346348,\n",
       "        0.0728869 , 0.06846532, 0.14469796, 0.13346348, 0.1       ,\n",
       "        0.1       , 0.1045825 , 0.0559017 , 0.15      , 0.1457738 ,\n",
       "        0.09682458, 0.06846532, 0.025     , 0.025     , 0.08477912,\n",
       "        0.08477912, 0.08477912, 0.08477912, 0.1       , 0.1       ,\n",
       "        0.03061862, 0.05      , 0.04677072, 0.04677072, 0.04677072,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03952847, 0.03061862, 0.03061862, 0.03061862, 0.05      ,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03061862, 0.03952847, 0.06373774, 0.0728869 , 0.0728869 ,\n",
       "        0.1879162 , 0.19605484, 0.13346348, 0.13346348, 0.13346348,\n",
       "        0.0728869 , 0.06846532, 0.14469796, 0.13346348, 0.1       ,\n",
       "        0.1       , 0.1045825 , 0.0559017 , 0.15      , 0.1457738 ,\n",
       "        0.09682458, 0.06846532, 0.025     , 0.025     , 0.08477912,\n",
       "        0.08477912, 0.08477912, 0.08477912, 0.1       , 0.1       ,\n",
       "        0.03061862, 0.05      , 0.04677072, 0.04677072, 0.04677072,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03952847, 0.03061862, 0.03061862, 0.03061862, 0.05      ,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.10155048, 0.10155048, 0.06846532, 0.0728869 , 0.0728869 ,\n",
       "        0.12869538, 0.13346348, 0.13346348, 0.13346348, 0.13346348,\n",
       "        0.06123724, 0.075     , 0.075     , 0.0728869 , 0.07905694,\n",
       "        0.08477912, 0.075     , 0.0559017 , 0.15      , 0.1457738 ,\n",
       "        0.05      , 0.05      , 0.08291562, 0.08291562, 0.08291562,\n",
       "        0.08477912, 0.08477912, 0.08477912, 0.1       , 0.1       ,\n",
       "        0.03061862, 0.03061862, 0.03061862, 0.03061862, 0.05      ,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "        0.03061862, 0.03061862, 0.03061862, 0.03061862, 0.04677072,\n",
       "        0.05      , 0.05      , 0.05      , 0.05      , 0.05      ]),\n",
       " 'rank_test_score': array([ 79,  61, 179, 149, 149, 231, 231, 259, 259, 259, 179, 245, 211,\n",
       "        225, 149, 149, 133, 251, 289, 295, 133, 133, 125, 125, 179, 179,\n",
       "        179, 179, 149, 149, 113,  79,  65,  65,  65,   1,   1,   1,   1,\n",
       "          1, 133,  79,  79,  79,  79,   1,   1,   1,   1,   1,  79,  61,\n",
       "        179, 149, 149, 231, 231, 259, 259, 259, 179, 245, 211, 225, 149,\n",
       "        149, 133, 251, 289, 295, 133, 133, 125, 125, 179, 179, 179, 179,\n",
       "        149, 149, 113,  79,  65,  65,  65,   1,   1,   1,   1,   1, 133,\n",
       "         79,  79,  79,  79,   1,   1,   1,   1,   1, 285, 285, 251, 259,\n",
       "        259, 283, 259, 259, 259, 259, 249, 231, 231, 225, 221, 245, 231,\n",
       "        251, 289, 295, 179, 179, 211, 211, 211, 179, 179, 179, 149, 149,\n",
       "        113, 113, 113, 113,  79,   1,   1,   1,   1,   1,  79,  79,  79,\n",
       "         79,  65,   1,   1,   1,   1,   1,  79,  61, 179, 149, 149, 231,\n",
       "        231, 259, 259, 259, 149, 221, 211, 225, 149, 149, 133, 251, 289,\n",
       "        295, 133, 133, 125, 125, 179, 179, 179, 179, 149, 149, 113,  79,\n",
       "         65,  65,  65,   1,   1,   1,   1,   1, 133,  79,  79,  79,  79,\n",
       "          1,   1,   1,   1,   1,  79,  61, 179, 149, 149, 231, 231, 259,\n",
       "        259, 259, 149, 221, 211, 225, 149, 149, 133, 251, 289, 295, 133,\n",
       "        133, 125, 125, 179, 179, 179, 179, 149, 149, 113,  79,  65,  65,\n",
       "         65,   1,   1,   1,   1,   1, 133,  79,  79,  79,  79,   1,   1,\n",
       "          1,   1,   1, 285, 285, 251, 259, 259, 283, 259, 259, 259, 259,\n",
       "        249, 231, 231, 225, 221, 245, 231, 251, 289, 295, 179, 179, 211,\n",
       "        211, 211, 179, 179, 179, 149, 149, 113, 113, 113, 113,  79,   1,\n",
       "          1,   1,   1,   1,  79,  79,  79,  79,  65,   1,   1,   1,   1,\n",
       "          1])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_is_fitted',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'iid',\n",
       " 'inverse_transform',\n",
       " 'multimetric_',\n",
       " 'n_iter',\n",
       " 'n_jobs',\n",
       " 'n_splits_',\n",
       " 'param_distributions',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'refit',\n",
       " 'refit_time_',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tree_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.96\n",
      "[[13  0]\n",
      " [ 1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.96        24\n",
      "   macro avg       0.96      0.95      0.96        24\n",
      "weighted avg       0.96      0.96      0.96        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn import tree\n",
    "\n",
    "df = pd.read_excel('D:/KKU/AjOff/AjOffData.xlsx',sheet_name='CutoffNorVsCCA')\n",
    "y=df.iloc[:,[3]]\n",
    "X=df.iloc[:,[4,5,6,7,8]]\n",
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "\n",
    "# Initiate the decision tree\n",
    "dt = DecisionTreeClassifier(max_depth=6)\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,[3]]\n",
    "X=df.iloc[:,[4,5,6,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Compute 5-fold cross-validation scores: cv_scores\n",
    "\n",
    "cv_scores = cross_val_score(reg,X,y,cv=5)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))\n",
    "text_representation = tree.export_text(dt)\n",
    "print(text_representation)\n",
    "##tree.plot_tree(dt)\n",
    "#plot_tree(dt, filled=True)\n",
    "#plt.figure(figsize=(90000,90000))\n",
    "#plt.show()\n",
    "\n",
    "#plot_tree(dt, filled=True)\n",
    "#fig = plt.gcf()\n",
    "#fig.set_size_inches(300, 200)\n",
    "#fig.savefig('D:/KKU/AjOff/tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class range in module builtins:\n",
      "\n",
      "class range(object)\n",
      " |  range(stop) -> range object\n",
      " |  range(start, stop[, step]) -> range object\n",
      " |  \n",
      " |  Return an object that produces a sequence of integers from start (inclusive)\n",
      " |  to stop (exclusive) by step.  range(i, j) produces i, i+1, i+2, ..., j-1.\n",
      " |  start defaults to 0, and stop is omitted!  range(4) produces 0, 1, 2, 3.\n",
      " |  These are exactly the valid indices for a list of 4 elements.\n",
      " |  When step is given, it specifies the increment (or decrement).\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self, /)\n",
      " |      self != 0\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __reversed__(...)\n",
      " |      Return a reverse iterator.\n",
      " |  \n",
      " |  count(...)\n",
      " |      rangeobject.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  index(...)\n",
      " |      rangeobject.index(value) -> integer -- return index of value.\n",
      " |      Raise ValueError if the value is not present.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  start\n",
      " |  \n",
      " |  step\n",
      " |  \n",
      " |  stop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 10)\n"
     ]
    }
   ],
   "source": [
    "print(range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
